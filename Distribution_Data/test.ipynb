{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from fastapi import APIRouter\n",
    "from fastapi.openapi.utils import get_openapi\n",
    "from fastapi import FastAPI,Response\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn\n",
    "from dotenv.main import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from numerize import numerize\n",
    "import datetime\n",
    "import _datetime\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "pd.options.mode.chained_assignment = None\n",
    "load_dotenv()\n",
    "\n",
    "my_server = os.environ['my_server']\n",
    "query_bridge = os.environ['query_multichain']\n",
    "\n",
    "DF_MULTICHAIN = pd.read_sql(query_bridge, my_server)\n",
    "'''FUNTION'''\n",
    "\n",
    "# Funtions\n",
    "\n",
    "\n",
    "def remove_number_string(df, str):\n",
    "    return df[str].map(lambda x: re.sub('[0-9]', '', x))\n",
    "# def filter data\n",
    "\n",
    "\n",
    "def Filter_data_duplicateValue(df, label, explorer):\n",
    "    ''' \n",
    "    CHỨC NĂNG: \n",
    "    - Sum value những Explorer trùng nhau\n",
    "\n",
    "    '''\n",
    "    tmp = df.loc[(df['LABEL'] == label) & (df['EXPLORER'] == explorer)]\n",
    "    return pd.DataFrame(tmp.groupby(['TIMESTAMP', 'CHAIN', 'LABEL', 'EXPLORER'])['VALUE'].sum()).reset_index()\n",
    "\n",
    "\n",
    "''' MERGE DATA HEADER & BODY'''\n",
    "\n",
    "n_label = DF_MULTICHAIN['LABEL'].unique()\n",
    "n_explorer = DF_MULTICHAIN['EXPLORER'].unique()\n",
    "DF_MULTICHAIN['TIMESTAMP'] = DF_MULTICHAIN['TIMESTAMP'].apply(\n",
    "    lambda x: pd.to_datetime(x).floor('T'))\n",
    "DF_MULTICHAIN['TIMESTAMP'] = pd.to_datetime(DF_MULTICHAIN['TIMESTAMP'])\n",
    "\n",
    "# ETH\n",
    "\n",
    "\n",
    "def processing_Data(DF_MULTICHAIN, n_label, n_explorer):\n",
    "    ETH_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[0])\n",
    "    ETH_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[0])\n",
    "    ETH_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[0])\n",
    "    # POLY\n",
    "    POLY_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[1])\n",
    "    POLY_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[1])\n",
    "    POLY_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[1])\n",
    "    # Moonriver\n",
    "    MOONRIVER_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[2])\n",
    "    MOONRIVER_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[2])\n",
    "    MOONRIVER_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[2])\n",
    "    # Moonbeam\n",
    "    MOONBEAM_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[3])\n",
    "    MOONBEAM_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[3])\n",
    "    MOONBEAM_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[3])\n",
    "    # Bscscan\n",
    "    BSCSCAN_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[4])\n",
    "    BSCSCAN_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[4])\n",
    "    BSCSCAN_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[4])\n",
    "    # Avalanchescan\n",
    "    AVALANCHE_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[5])\n",
    "    AVALANCHE_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[5])\n",
    "    AVALANCHE_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[5])\n",
    "    # Fantomscan\n",
    "    FTM_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[6])\n",
    "    FTM_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[6])\n",
    "    FTM_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[6])\n",
    "    # optimism\n",
    "    OP_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[7])\n",
    "    OP_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[7])\n",
    "    # arbitrum\n",
    "    AR_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[8])\n",
    "    # Kavascan\n",
    "    KAVA_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[9])\n",
    "    KAVA_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[9])\n",
    "    KAVA_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[9])\n",
    "    # Dogechain\n",
    "    DOGE_USDT = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[0], n_explorer[10])\n",
    "    DOGE_USDC = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[1], n_explorer[10])\n",
    "    DOGE_BUSD = Filter_data_duplicateValue(\n",
    "        DF_MULTICHAIN, n_label[2], n_explorer[10])\n",
    "\n",
    "    # ETH SUM\n",
    "    Frames_eth = [ETH_USDT, ETH_USDC, ETH_BUSD]\n",
    "    ETH_S = pd.concat(Frames_eth)\n",
    "    # Poly\n",
    "    Frames_poly = [POLY_USDT, POLY_USDC, POLY_BUSD]\n",
    "    POLY_S = pd.concat(Frames_poly)\n",
    "    POLY_S\n",
    "    # Moonriver\n",
    "    Frams_Moonriver = [MOONRIVER_USDT, MOONRIVER_USDC, MOONRIVER_BUSD]\n",
    "    MOONRI_S = pd.concat(Frams_Moonriver)\n",
    "    # Moonbeam\n",
    "    Frames_Moonbeam = [MOONBEAM_USDT, MOONBEAM_USDC, MOONBEAM_BUSD]\n",
    "    MOONBEAM_S = pd.concat(Frames_Moonbeam)\n",
    "    # Bscscan\n",
    "    Frames_bscscan = [BSCSCAN_USDT, BSCSCAN_USDC, BSCSCAN_BUSD]\n",
    "    BSCSCAN_S = pd.concat(Frames_bscscan)\n",
    "\n",
    "    # Avalanche\n",
    "    Frames_avalanche = [AVALANCHE_USDT, AVALANCHE_USDC, AVALANCHE_BUSD]\n",
    "    AVALAN_S = pd.concat(Frames_avalanche)\n",
    "    # FTMScan\n",
    "    Frames_FTM = [FTM_USDT, FTM_USDC, FTM_BUSD]\n",
    "    FTM_S = pd.concat(Frames_FTM)\n",
    "    # OPtimism\n",
    "    Frames_OPti = [OP_USDT, OP_USDC]\n",
    "    OPTI_S = pd.concat(Frames_OPti)\n",
    "    # Arbiscan\n",
    "    AR_USDT\n",
    "\n",
    "    # Kavascan\n",
    "    Frames_kava = [KAVA_USDT, KAVA_USDC, KAVA_BUSD]\n",
    "    KAVA_S = pd.concat(Frames_kava)\n",
    "\n",
    "    # Dogechain\n",
    "    Frames_Doge = [DOGE_USDT, DOGE_USDC, DOGE_BUSD]\n",
    "    DOGE_S = pd.concat(Frames_Doge)\n",
    "\n",
    "    Frames_all = [ETH_S, POLY_S, MOONRI_S, MOONBEAM_S, BSCSCAN_S,\n",
    "                  AVALAN_S, FTM_S, OPTI_S, AR_USDT, KAVA_S, DOGE_S]\n",
    "    DF_MULTICHAIN_V1 = pd.concat(Frames_all)\n",
    "    return DF_MULTICHAIN_V1\n",
    "\n",
    "\n",
    "def proces_Data_Multichain():\n",
    "    DATA = processing_Data(DF_MULTICHAIN, n_label, n_explorer)\n",
    "    return DATA\n",
    "\n",
    "# Bridge_Mul = proces_Data_Multichain()\n",
    "\n",
    "def TOTAL_ASSETS(data, explorer):\n",
    "    ''' \n",
    "    FUNTION: Summary all value stabelcoin the same explorer and transfer another dataframe\n",
    "    '''\n",
    "    tmp = data[data['EXPLORER'] == explorer]\n",
    "    tmp = tmp.groupby(['TIMESTAMP', 'LABEL'])['VALUE'].sum().reset_index()\n",
    "    tmp = tmp.groupby(['TIMESTAMP'])['VALUE'].sum().reset_index()\n",
    "    tmp['EXPLORER'] = explorer\n",
    "    return tmp\n",
    "def rename(data):\n",
    "    data['EXPLORER'] = data['EXPLORER'].replace({'Etherscan':'Ethereum','Polygonscan':'Polygon','Bscscan':'BSC','Avalanchescan':'Avalanche','Fantomscan':'Fantom','Kavascan':'Kava'})\n",
    "    return data\n",
    "\n",
    "\n",
    "Bridge_line = proces_Data_Multichain()\n",
    "Bridge_line = rename(Bridge_line)\n",
    "Etherscan = TOTAL_ASSETS(Bridge_line,'Ethereum')\n",
    "Polygonscan = TOTAL_ASSETS(Bridge_line,'Polygon')\n",
    "Moonriver = TOTAL_ASSETS(Bridge_line,'Moonriver')\n",
    "Moonbeam = TOTAL_ASSETS(Bridge_line,'Moonbeam')\n",
    "Bscscan = TOTAL_ASSETS(Bridge_line,'BSC')\n",
    "Avalanchescan = TOTAL_ASSETS(Bridge_line,'Avalanche')\n",
    "Fantomscan = TOTAL_ASSETS(Bridge_line,'Fantom')\n",
    "Optimsm = TOTAL_ASSETS(Bridge_line,'Optimsm')\n",
    "Arbitrum = TOTAL_ASSETS(Bridge_line,'Arbitrum')\n",
    "Kavascan = TOTAL_ASSETS(Bridge_line,'Kava')\n",
    "Dogechain = TOTAL_ASSETS(Bridge_line,'Dogechain')\n",
    "TOTAL_MULTICHAIN = pd.concat([Etherscan,Polygonscan,Moonriver,Moonbeam,Bscscan,Avalanchescan,Fantomscan,Optimsm,Arbitrum,Kavascan,Dogechain])\n",
    "def create_multichain(data):\n",
    "    cols = ['TIMESTAMP','VALUE','EXPLORER']\n",
    "    data = data[cols]\n",
    "    data =data.groupby(['TIMESTAMP','EXPLORER'])['VALUE'].sum()\n",
    "    data = data.reset_index()\n",
    "    # data = data.sort_values(by=['VALUE'],ascending=False)\n",
    "    return data\n",
    "\n",
    "# eposo\n",
    "\n",
    "\n",
    "# Celer cBridge\n",
    "query_celer_cbridge = os.environ['query_celer_cBridge']\n",
    "\n",
    "Celer_cBridge = pd.read_sql(query_celer_cbridge,my_server)\n",
    "\n",
    "Celer_cBridge['TIMESTAMP']=Celer_cBridge['TIMESTAMP'].apply(lambda x : pd.to_datetime(x).floor('T'))\n",
    "Celer_cBridge['TIMESTAMP'] = pd.to_datetime(Celer_cBridge['TIMESTAMP'])\n",
    "\n",
    "Celer_cBridge['EXPLORER'] = Celer_cBridge['EXPLORER'].replace({'Polygonscan':'Polygon','Bscscan':'BSC','Avalanchescan':'Avalanche','Fantomscan':'Fantom'})\n",
    "#line total assets\n",
    "def create_celer(data):\n",
    "    TOTAL_ASSETS_CELER =data.groupby(['TIMESTAMP','EXPLORER'])['VALUE'].sum()\n",
    "    TOTAL_ASSETS_CELER = TOTAL_ASSETS_CELER.reset_index()\n",
    "    # TOTAL_ASSETS_CELER = TOTAL_ASSETS_CELER.sort_values(by=['VALUE'])\n",
    "    return TOTAL_ASSETS_CELER\n",
    "\n",
    "\n",
    "# Hop bridge\n",
    "query_hop_bridge = os.environ['query_hop_bridge']\n",
    "HOP = pd.read_sql(query_hop_bridge,my_server)\n",
    "\n",
    "HOP['TIMESTAMP']=HOP['TIMESTAMP'].apply(lambda x : pd.to_datetime(x).floor('T'))\n",
    "HOP['TIMESTAMP'] = pd.to_datetime(HOP['TIMESTAMP'])\n",
    "\n",
    "\n",
    "#Line total\n",
    "def create_hop(data):\n",
    "    cols = ['TIMESTAMP','VALUE','EXPLORER']\n",
    "    TOTAL_ASSETS_HOP = data.groupby(['TIMESTAMP','EXPLORER'])['VALUE'].sum()\n",
    "    TOTAL_ASSETS_HOP = TOTAL_ASSETS_HOP.reset_index()\n",
    "    # TOTAL_ASSETS_HOP = TOTAL_ASSETS_HOP.sort_values(by=['VALUE'])\n",
    "    TOTAL_ASSETS_HOP = TOTAL_ASSETS_HOP[cols]\n",
    "    TOTAL_ASSETS_HOP= rename(TOTAL_ASSETS_HOP)\n",
    "    return TOTAL_ASSETS_HOP\n",
    "\n",
    "\n",
    "# Startgate\n",
    "query_stargate = os.environ['query_Stargate_bridge']\n",
    "\n",
    "STARGATE = pd.read_sql(query_stargate,my_server)\n",
    "STARGATE = STARGATE.rename(columns={'TIMSTAMP':'TIMESTAMP'})\n",
    "\n",
    "STARGATE['TIMESTAMP']=STARGATE['TIMESTAMP'].apply(lambda x : pd.to_datetime(x).floor('T'))\n",
    "STARGATE['TIMESTAMP'] = pd.to_datetime(STARGATE['TIMESTAMP'])\n",
    "\n",
    "#line total assets\n",
    "def create_starage(data):\n",
    "    cols = ['TIMESTAMP','VALUE','EXPLORER']\n",
    "    TOTAL_ASSETS_STARGATE =data.groupby(['TIMESTAMP','EXPLORER'])['VALUE'].sum()\n",
    "    TOTAL_ASSETS_STARGATE = TOTAL_ASSETS_STARGATE.reset_index()\n",
    "    # TOTAL_ASSETS_STARGATE = TOTAL_ASSETS_STARGATE.sort_values(by=['VALUE'])\n",
    "    TOTAL_ASSETS_STARGATE = TOTAL_ASSETS_STARGATE[cols]\n",
    "    TOTAL_ASSETS_STARGATE = rename(TOTAL_ASSETS_STARGATE)\n",
    "    return TOTAL_ASSETS_STARGATE\n",
    "\n",
    "#Synapse\n",
    "query_synapse = os.getenv('query_synapse_bridge')\n",
    "\n",
    "SYNAPSE = pd.read_sql(query_synapse,my_server)\n",
    "SYNAPSE['TIMESTAMP']=SYNAPSE['TIMESTAMP'].apply(lambda x : pd.to_datetime(x).floor('T'))\n",
    "SYNAPSE['TIMESTAMP'] = pd.to_datetime(SYNAPSE['TIMESTAMP'])\n",
    "\n",
    "def create_synapse(data):\n",
    "\n",
    "    cols = ['TIMESTAMP','VALUE','EXPLORER']\n",
    "\n",
    "    TOTAL_ASSETS_SYNAPSE =SYNAPSE.groupby(['TIMESTAMP','EXPLORER'])['VALUE'].sum()\n",
    "    TOTAL_ASSETS_SYNAPSE = TOTAL_ASSETS_SYNAPSE.reset_index()\n",
    "    # TOTAL_ASSETS_SYNAPSE = TOTAL_ASSETS_SYNAPSE.sort_values(by=['VALUE'])\n",
    "    TOTAL_ASSETS_SYNAPSE = TOTAL_ASSETS_SYNAPSE[cols]\n",
    "    TOTAL_ASSETS_SYNAPSE = rename(TOTAL_ASSETS_SYNAPSE)\n",
    "    return TOTAL_ASSETS_SYNAPSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# table in header ovewrview\n",
    "multichain_table = create_multichain(TOTAL_MULTICHAIN)\n",
    "multichain_table = multichain_table.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()\n",
    "\n",
    "celer_table = create_celer(Celer_cBridge)\n",
    "celer_table = celer_table.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()\n",
    "hop_table = create_hop(HOP)\n",
    "hop_table = hop_table.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()\n",
    "stargate_table = create_starage(STARGATE)\n",
    "stargate_table = stargate_table.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()\n",
    "synapse_table = create_synapse(SYNAPSE)\n",
    "synapse_table = synapse_table.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()\n",
    "\n",
    "def create_table_bridge_st(data):\n",
    "    hientai = data[data['TIMESTAMP']== data['TIMESTAMP'].max()]['VALUE']\n",
    "    # hientai = hientai.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()['VALUE']\n",
    "    qk_data = data.set_index('TIMESTAMP')\n",
    "    qk_data = qk_data.between_time('6:00', '10:59')\n",
    "    qk_data = qk_data.reset_index()\n",
    "    qk_data['TIMESTAMP'] = pd.to_datetime(qk_data['TIMESTAMP']).dt.date\n",
    "\n",
    "    lastday = qk_data[qk_data['TIMESTAMP']== qk_data['TIMESTAMP'].max() - datetime.timedelta(days=1)]['VALUE']\n",
    "    lastweek = qk_data[qk_data['TIMESTAMP']== qk_data['TIMESTAMP'].max() - datetime.timedelta(days=7)]['VALUE']\n",
    "    lastmonth = qk_data[qk_data['TIMESTAMP']== qk_data['TIMESTAMP'].max() - datetime.timedelta(days=30)]['VALUE']\n",
    "    df_table = pd.DataFrame({\n",
    "        'changeVL_24h':[float(hientai)-float(lastday)],\n",
    "        'per_24h':[((float(hientai)-float(lastday))/float(hientai))*100],\n",
    "        'changeVL_7d':[float(hientai)-float(lastweek)],\n",
    "        'per_7D':[((float(hientai)-float(lastweek))/float(hientai))*100],\n",
    "        'change_30d':[float(hientai)-float(lastmonth)],\n",
    "        'per_30D':[((float(hientai)-float(lastmonth))/float(hientai))*100],\n",
    "    })\n",
    "    return df_table.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = synapse_table\n",
    "hientai = data[data['TIMESTAMP']== data['TIMESTAMP'].max()]['VALUE']\n",
    "# hientai = hientai.groupby(['TIMESTAMP']).agg({'VALUE':'sum'}).reset_index()['VALUE']\n",
    "qk_data = data.set_index('TIMESTAMP')\n",
    "qk_data = qk_data.between_time('6:00', '10:59')\n",
    "qk_data = qk_data.reset_index()\n",
    "qk_data['TIMESTAMP'] = pd.to_datetime(qk_data['TIMESTAMP']).dt.date\n",
    "\n",
    "lastday = qk_data[qk_data['TIMESTAMP']== qk_data['TIMESTAMP'].max() - datetime.timedelta(days=1)]['VALUE']\n",
    "lastweek = qk_data[qk_data['TIMESTAMP']== qk_data['TIMESTAMP'].max() - datetime.timedelta(days=7)]['VALUE']\n",
    "lastmonth = qk_data[qk_data['TIMESTAMP']== qk_data['TIMESTAMP'].max() - datetime.timedelta(days=30)]['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>2.268818e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>2.199441e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>2.157929e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2023-09-13</td>\n",
       "      <td>2.017586e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.024459e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2023-09-15</td>\n",
       "      <td>2.021289e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>1.809112e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2023-09-17</td>\n",
       "      <td>1.807524e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>1.793075e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>1.849585e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>1.866594e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2023-09-22</td>\n",
       "      <td>1.865630e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2023-09-23</td>\n",
       "      <td>1.879770e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>1.882438e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>1.875523e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>1.886682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>1.882445e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>1.853143e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>1.848067e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2023-10-03</td>\n",
       "      <td>1.849764e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2023-10-04</td>\n",
       "      <td>1.871152e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>1.819203e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>1.814473e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>1.815332e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>1.813408e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>1.817414e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>1.810240e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>1.805353e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>1.783273e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2023-10-17</td>\n",
       "      <td>1.742108e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TIMESTAMP         VALUE\n",
       "107  2023-09-06  2.268818e+07\n",
       "108  2023-09-09  2.199441e+07\n",
       "109  2023-09-12  2.157929e+07\n",
       "110  2023-09-13  2.017586e+07\n",
       "111  2023-09-14  2.024459e+07\n",
       "112  2023-09-15  2.021289e+07\n",
       "113  2023-09-16  1.809112e+07\n",
       "114  2023-09-17  1.807524e+07\n",
       "115  2023-09-18  1.793075e+07\n",
       "116  2023-09-20  1.849585e+07\n",
       "117  2023-09-21  1.866594e+07\n",
       "118  2023-09-22  1.865630e+07\n",
       "119  2023-09-23  1.879770e+07\n",
       "120  2023-09-24  1.882438e+07\n",
       "121  2023-09-25  1.875523e+07\n",
       "122  2023-09-27  1.886682e+07\n",
       "123  2023-09-28  1.882445e+07\n",
       "124  2023-09-30  1.853143e+07\n",
       "125  2023-10-02  1.848067e+07\n",
       "126  2023-10-03  1.849764e+07\n",
       "127  2023-10-04  1.871152e+07\n",
       "128  2023-10-06  1.819203e+07\n",
       "129  2023-10-07  1.814473e+07\n",
       "130  2023-10-09  1.815332e+07\n",
       "131  2023-10-11  1.813408e+07\n",
       "132  2023-10-13  1.817414e+07\n",
       "133  2023-10-14  1.810240e+07\n",
       "134  2023-10-15  1.805353e+07\n",
       "135  2023-10-16  1.783273e+07\n",
       "136  2023-10-17  1.742108e+07"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk_data.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
